{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27f9b0f-a152-483b-84a0-4cf2ec864a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import detectron2\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data.transforms import Transform\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper, build_detection_train_loader\n",
    "from detectron2.modeling import build_model,build_resnet_backbone,build_backbone\n",
    "from detectron2.structures import ImageList, Instances\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling.meta_arch.rcnn import GeneralizedRCNN\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced8c77-39fe-421e-b451-39f180e207d8",
   "metadata": {},
   "source": [
    "- Contrast normalization: The myeloma cells have varying levels of contrast as compared to other cells and tissues, so normalizing the contrast can help them be more visible\n",
    "- Morphological operations: Erosion or dilation operations can smooth the edges of the cells can help us detect the cancer cells better\n",
    "- Gradient Filters: Sobel filter can help identify the boundaries of the cells better\n",
    "- Color Channels: Manipulate the different color channels (RGB) of the image by suppressing or enhancing the effect of either red, green, or blue channel\n",
    "- Blur Filter: Try the Gaussian blur filters to smooth the image and reduce the noise\n",
    "- Resolution: Benchmark the accuracy of detecting myeloma cells by reducing the resolution of the image to see if we can get at par accuracy with a smaller dimension image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204480d-9793-4b34-a36b-be3ccd36de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.transforms.ColorTransform\n",
    "# data.transforms.RandomBrightness\n",
    "# data.transforms.RandomContrast\n",
    "# data.transforms.RandomSaturation\n",
    "# data.transforms.RandomLighting\n",
    "\n",
    "# ColorTransform(brightness_delta=20, contrast_range=(0.8, 1.2), saturation_range=(0.8, 1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a75634-7471-4759-8d3a-10f907f46a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrectColor(Transform):\n",
    "    \"\"\"\n",
    "    Color correct the input image to RGB format\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def apply_image(self, img):\n",
    "        ## Convert image to RGB format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "\n",
    "    def apply_coords(self, coords):\n",
    "        # This transform does not modify the bounding box coordinates\n",
    "        return coords\n",
    "\n",
    "    def get_transform(self, image):\n",
    "        # This transform does not depend on the input image\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc767851-eabf-472f-8973-46416b7d6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(Transform):\n",
    "    \"\"\"\n",
    "    Apply a Gaussian blur to the input image.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=(15, 15), sigma=0.0):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def apply_image(self, img):        \n",
    "        ## apply Gaussian kernel\n",
    "        img = cv2.GaussianBlur(img, self.kernel_size, self.sigma)\n",
    "        return img\n",
    "\n",
    "    def apply_coords(self, coords):\n",
    "        # This transform does not modify the bounding box coordinates\n",
    "        return coords\n",
    "\n",
    "    def get_transform(self, image):\n",
    "        # This transform does not depend on the input image\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fead9-ff6b-4f1d-9dda-252273bed88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = CorrectColor()\n",
    "# im = cv2.imread(\"../TCIA_SegPC_dataset/coco/x/106.bmp\")\n",
    "# im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(im);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3facc61-99c9-48c5-8375-efe960682348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im1 = abc.apply_image(im)\n",
    "# plt.imshow(im1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc74e3d-5f4c-4b1f-98f8-93f243b4fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sem_seg_train_aug(cfg):\n",
    "    \"\"\"\n",
    "    Define a list of augmentations to apply to the images.\n",
    "    \"\"\"\n",
    "    \n",
    "    augs= [CorrectColor(), GaussianBlur()]\n",
    "    \n",
    "    return augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f84bf-6295-4cd0-b09d-cf84219abd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"SegPC_train\", {}, \"../TCIA_SegPC_dataset/coco/COCO.json\", \"../TCIA_SegPC_dataset/coco/x/\")\n",
    "register_coco_instances(\"SegPC_val\", {}, \"../TCIA_SegPC_dataset/coco_val/COCO.json\", \"../TCIA_SegPC_dataset/coco_val/x/\")\n",
    "\n",
    "train_meta = MetadataCatalog.get('SegPC_train')\n",
    "val_meta = MetadataCatalog.get('SegPC_val')\n",
    "\n",
    "train_dicts = DatasetCatalog.get(\"SegPC_train\")\n",
    "val_dicts = DatasetCatalog.get(\"SegPC_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731bddc-dd0c-4f17-b89b-65a7ddafc358",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"SegPC_train\",)\n",
    "cfg.DATASETS.TEST = (\"SegPC_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\")  \n",
    "cfg.SOLVER.IMS_PER_BATCH = 3\n",
    "cfg.SOLVER.BASE_LR = 0.02/8\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = 'WarmupCosineLR'\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 1500\n",
    "cfg.SOLVER.MAX_ITER = 2000\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 250\n",
    "\n",
    "cfg.CUDNN_BENCHMARK = True\n",
    "cfg.OUTPUT_DIR = \"./output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f2b24-8f91-46ce-a71f-f8011198b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        \n",
    "        mapper = DatasetMapper(cfg, is_train=True, augmentations=build_sem_seg_train_aug(cfg))\n",
    "        \n",
    "        return build_detection_train_loader(cfg, mapper=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d53dc2-dc32-49f8-87e5-33340b74cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f52bf-2bfd-4ddb-914b-80fa8b227d0f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a759c1-dfb1-4d1b-a1e1-30202c5132b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "\n",
    "# for d in random.sample(train_dicts, 3):\n",
    "#     print(d[\"file_name\"])\n",
    "#     img = cv2.imread(d[\"file_name\"])\n",
    "#     visualizer = Visualizer(img[:, :, ::-1], metadata=train_meta, instance_mode=ColorMode.IMAGE_BW, scale=1)\n",
    "#     out = visualizer.draw_dataset_dict(d)\n",
    "#     plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e89c6-b0fd-4aec-80e5-3292f2732bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
