{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27f9b0f-a152-483b-84a0-4cf2ec864a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import detectron2\n",
    "from detectron2.modeling import BACKBONE_REGISTRY, Backbone, ShapeSpec\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data.transforms import Transform\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper, build_detection_train_loader, build_detection_test_loader\n",
    "from detectron2.modeling import build_model,build_resnet_backbone,build_backbone\n",
    "from detectron2.structures import ImageList, Instances\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling.meta_arch.rcnn import GeneralizedRCNN\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from segmentation_models_pytorch.encoders import get_encoder\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced8c77-39fe-421e-b451-39f180e207d8",
   "metadata": {},
   "source": [
    "## Blur Filter: Try the Gaussian blur filters to smooth the image and reduce the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc767851-eabf-472f-8973-46416b7d6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc74e3d-5f4c-4b1f-98f8-93f243b4fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sem_seg_train_aug(cfg):\n",
    "    \"\"\"\n",
    "    Define a list of augmentations to apply to the images.\n",
    "    \"\"\"\n",
    "    \n",
    "    augs= [GaussianBlur()]\n",
    "    \n",
    "    return augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026f84bf-6295-4cd0-b09d-cf84219abd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/28 21:49:41 d2.data.datasets.coco]: Loaded 298 images in COCO format from ../TCIA_SegPC_dataset/coco/COCO.json\n",
      "[04/28 21:49:41 d2.data.datasets.coco]: Loaded 200 images in COCO format from ../TCIA_SegPC_dataset/coco_val/COCO.json\n"
     ]
    }
   ],
   "source": [
    "register_coco_instances(\"SegPC_train\", {}, \"../TCIA_SegPC_dataset/coco/COCO.json\", \"../TCIA_SegPC_dataset/coco/x/\")\n",
    "register_coco_instances(\"SegPC_val\", {}, \"../TCIA_SegPC_dataset/coco_val/COCO.json\", \"../TCIA_SegPC_dataset/coco_val/x/\")\n",
    "\n",
    "train_meta = MetadataCatalog.get('SegPC_train')\n",
    "val_meta = MetadataCatalog.get('SegPC_val')\n",
    "\n",
    "train_dicts = DatasetCatalog.get(\"SegPC_train\")\n",
    "val_dicts = DatasetCatalog.get(\"SegPC_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6595130d-eaf3-46cd-b41b-fc9f0be13462",
   "metadata": {},
   "outputs": [],
   "source": [
    "@BACKBONE_REGISTRY.register()\n",
    "class Effb5(Backbone):\n",
    "    def __init__(self, cfg, input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Set up the illumination layer\n",
    "#         self.illumination = nn.Conv2d(in_channels=3, out_channels=9, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "#         torch.nn.init.normal_(self.illumination.weight, mean=0.0, std=0.05)\n",
    "#         in_channels = 1\n",
    "        \n",
    "        in_channels = 3\n",
    "        encoder_name = 'timm-efficientnet-b5'\n",
    "        encoder_depth = 5\n",
    "        encoder_weights = 'noisy-student'\n",
    "        self.encoder = get_encoder(encoder_name,\n",
    "                in_channels=in_channels,\n",
    "                depth=encoder_depth,\n",
    "                weights=encoder_weights)\n",
    "        self.channels = self.encoder.out_channels\n",
    "        self.conv = nn.ModuleList(\n",
    "            [nn.Conv2d(self.channels[i],256,3,stride = 2, padding = 1) for i in range(len(self.channels))]\n",
    "        )\n",
    "\n",
    "        self.names = [\"p\"+str(i+1) for i in range(6)]\n",
    "        \n",
    "    def forward(self, image):\n",
    "\n",
    "#         illuminated_image = torch.sum(self.illumination(image), dim=1, keepdim=True)\n",
    "#         features = self.encoder(illuminated_image)\n",
    "        features = self.encoder(image)\n",
    "        out = {self.names[i]: self.conv[i](features[i]) for i in range(1, len(features))}\n",
    "\n",
    "        return out\n",
    "    def output_shape(self):\n",
    "        out_shape = {self.names[i]: ShapeSpec(channels =256, stride = 2**(i+1)) for i in range(1, len(self.names))}\n",
    "        return out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5731bddc-dd0c-4f17-b89b-65a7ddafc358",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"SegPC_train\",)\n",
    "cfg.DATASETS.TEST = (\"SegPC_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 5\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\")  \n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.02/8\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = 'WarmupCosineLR'\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 100\n",
    "cfg.SOLVER.MAX_ITER = 3725\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 250\n",
    "cfg.MODEL.BACKBONE.NAME = \"Effb5\"\n",
    "\n",
    "cfg.CUDNN_BENCHMARK = True\n",
    "cfg.OUTPUT_DIR = \"./output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769f2b24-8f91-46ce-a71f-f8011198b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        \n",
    "        mapper = DatasetMapper(cfg, is_train=True, augmentations=build_sem_seg_train_aug(cfg))\n",
    "        \n",
    "        return build_detection_train_loader(cfg, mapper=mapper)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_test_loader(cls, cfg, dataset_name):\n",
    "        \n",
    "        mapper = DatasetMapper(cfg, is_train=False, augmentations=build_sem_seg_train_aug(cfg))\n",
    "        \n",
    "        return build_detection_test_loader(cfg, dataset_name, mapper=mapper)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d53dc2-dc32-49f8-87e5-33340b74cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f52bf-2bfd-4ddb-914b-80fa8b227d0f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/28 21:49:48 d2.engine.defaults]: Model:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): Effb5(\n",
      "    (encoder): EfficientNetEncoder(\n",
      "      (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNormAct2d(\n",
      "        48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (drop): Identity()\n",
      "        (act): Swish()\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): DepthwiseSeparableConv(\n",
      "            (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): DepthwiseSeparableConv(\n",
      "            (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.005)\n",
      "          )\n",
      "          (2): DepthwiseSeparableConv(\n",
      "            (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.010)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.015)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.021)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.026)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.031)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.036)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.041)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.046)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.051)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.056)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.062)\n",
      "          )\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.067)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.072)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.077)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.082)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.087)\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.092)\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.097)\n",
      "          )\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.103)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.108)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.113)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.118)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.123)\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.128)\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.133)\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.138)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.144)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.149)\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.154)\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.159)\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.164)\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.169)\n",
      "          )\n",
      "          (7): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.174)\n",
      "          )\n",
      "          (8): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.179)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.185)\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.190)\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Swish()\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): Swish()\n",
      "              (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.195)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_head): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNormAct2d(\n",
      "        2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (drop): Identity()\n",
      "        (act): Swish()\n",
      "      )\n",
      "      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    )\n",
      "    (conv): ModuleList(\n",
      "      (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): Conv2d(48, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (2): Conv2d(40, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (3): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (4): Conv2d(176, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): Conv2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "      (1): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "      (2): FastRCNNConvFCHead(\n",
      "        (conv1): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (conv4): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (1): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn5): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn6): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn7): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn8): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[04/28 21:49:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [GaussianBlur()]\n",
      "[04/28 21:49:48 d2.data.datasets.coco]: Loaded 298 images in COCO format from ../TCIA_SegPC_dataset/coco/COCO.json\n",
      "[04/28 21:49:48 d2.data.build]: Removed 0 images with no usable annotations. 298 images left.\n",
      "[04/28 21:49:48 d2.data.build]: Distribution of instances among all 1 categories:\n",
      "|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    cell    | 1643         |\n",
      "|            |              |\n",
      "[04/28 21:49:48 d2.data.build]: Using training sampler TrainingSampler\n",
      "[04/28 21:49:48 d2.data.common]: Serializing 298 elements to byte tensors and concatenating them all ...\n",
      "[04/28 21:49:48 d2.data.common]: Serialized dataset takes 21.26 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "backbone.conv.0.{bias, weight}\n",
      "backbone.conv.1.{bias, weight}\n",
      "backbone.conv.2.{bias, weight}\n",
      "backbone.conv.3.{bias, weight}\n",
      "backbone.conv.4.{bias, weight}\n",
      "backbone.conv.5.{bias, weight}\n",
      "backbone.encoder.blocks.0.0.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.0.0.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.0.0.conv_dw.weight\n",
      "backbone.encoder.blocks.0.0.conv_pw.weight\n",
      "backbone.encoder.blocks.0.0.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.0.0.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.0.1.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.0.1.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.0.1.conv_dw.weight\n",
      "backbone.encoder.blocks.0.1.conv_pw.weight\n",
      "backbone.encoder.blocks.0.1.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.0.1.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.0.2.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.0.2.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.0.2.conv_dw.weight\n",
      "backbone.encoder.blocks.0.2.conv_pw.weight\n",
      "backbone.encoder.blocks.0.2.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.0.2.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.1.0.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.0.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.0.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.0.conv_dw.weight\n",
      "backbone.encoder.blocks.1.0.conv_pw.weight\n",
      "backbone.encoder.blocks.1.0.conv_pwl.weight\n",
      "backbone.encoder.blocks.1.0.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.1.0.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.1.1.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.1.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.1.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.1.conv_dw.weight\n",
      "backbone.encoder.blocks.1.1.conv_pw.weight\n",
      "backbone.encoder.blocks.1.1.conv_pwl.weight\n",
      "backbone.encoder.blocks.1.1.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.1.1.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.1.2.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.2.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.2.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.2.conv_dw.weight\n",
      "backbone.encoder.blocks.1.2.conv_pw.weight\n",
      "backbone.encoder.blocks.1.2.conv_pwl.weight\n",
      "backbone.encoder.blocks.1.2.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.1.2.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.1.3.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.3.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.3.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.3.conv_dw.weight\n",
      "backbone.encoder.blocks.1.3.conv_pw.weight\n",
      "backbone.encoder.blocks.1.3.conv_pwl.weight\n",
      "backbone.encoder.blocks.1.3.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.1.3.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.1.4.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.4.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.4.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.1.4.conv_dw.weight\n",
      "backbone.encoder.blocks.1.4.conv_pw.weight\n",
      "backbone.encoder.blocks.1.4.conv_pwl.weight\n",
      "backbone.encoder.blocks.1.4.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.1.4.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.2.0.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.0.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.0.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.0.conv_dw.weight\n",
      "backbone.encoder.blocks.2.0.conv_pw.weight\n",
      "backbone.encoder.blocks.2.0.conv_pwl.weight\n",
      "backbone.encoder.blocks.2.0.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.2.0.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.2.1.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.1.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.1.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.1.conv_dw.weight\n",
      "backbone.encoder.blocks.2.1.conv_pw.weight\n",
      "backbone.encoder.blocks.2.1.conv_pwl.weight\n",
      "backbone.encoder.blocks.2.1.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.2.1.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.2.2.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.2.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.2.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.2.conv_dw.weight\n",
      "backbone.encoder.blocks.2.2.conv_pw.weight\n",
      "backbone.encoder.blocks.2.2.conv_pwl.weight\n",
      "backbone.encoder.blocks.2.2.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.2.2.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.2.3.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.3.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.3.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.3.conv_dw.weight\n",
      "backbone.encoder.blocks.2.3.conv_pw.weight\n",
      "backbone.encoder.blocks.2.3.conv_pwl.weight\n",
      "backbone.encoder.blocks.2.3.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.2.3.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.2.4.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.4.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.4.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.2.4.conv_dw.weight\n",
      "backbone.encoder.blocks.2.4.conv_pw.weight\n",
      "backbone.encoder.blocks.2.4.conv_pwl.weight\n",
      "backbone.encoder.blocks.2.4.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.2.4.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.3.0.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.0.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.0.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.0.conv_dw.weight\n",
      "backbone.encoder.blocks.3.0.conv_pw.weight\n",
      "backbone.encoder.blocks.3.0.conv_pwl.weight\n",
      "backbone.encoder.blocks.3.0.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.3.0.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.3.1.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.1.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.1.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.1.conv_dw.weight\n",
      "backbone.encoder.blocks.3.1.conv_pw.weight\n",
      "backbone.encoder.blocks.3.1.conv_pwl.weight\n",
      "backbone.encoder.blocks.3.1.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.3.1.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.3.2.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.2.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.2.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.2.conv_dw.weight\n",
      "backbone.encoder.blocks.3.2.conv_pw.weight\n",
      "backbone.encoder.blocks.3.2.conv_pwl.weight\n",
      "backbone.encoder.blocks.3.2.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.3.2.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.3.3.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.3.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.3.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.3.conv_dw.weight\n",
      "backbone.encoder.blocks.3.3.conv_pw.weight\n",
      "backbone.encoder.blocks.3.3.conv_pwl.weight\n",
      "backbone.encoder.blocks.3.3.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.3.3.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.3.4.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.4.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.4.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.4.conv_dw.weight\n",
      "backbone.encoder.blocks.3.4.conv_pw.weight\n",
      "backbone.encoder.blocks.3.4.conv_pwl.weight\n",
      "backbone.encoder.blocks.3.4.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.3.4.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.3.5.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.5.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.5.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.5.conv_dw.weight\n",
      "backbone.encoder.blocks.3.5.conv_pw.weight\n",
      "backbone.encoder.blocks.3.5.conv_pwl.weight\n",
      "backbone.encoder.blocks.3.5.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.3.5.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.3.6.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.6.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.6.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.3.6.conv_dw.weight\n",
      "backbone.encoder.blocks.3.6.conv_pw.weight\n",
      "backbone.encoder.blocks.3.6.conv_pwl.weight\n",
      "backbone.encoder.blocks.3.6.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.3.6.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.4.0.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.0.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.0.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.0.conv_dw.weight\n",
      "backbone.encoder.blocks.4.0.conv_pw.weight\n",
      "backbone.encoder.blocks.4.0.conv_pwl.weight\n",
      "backbone.encoder.blocks.4.0.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.4.0.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.4.1.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.1.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.1.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.1.conv_dw.weight\n",
      "backbone.encoder.blocks.4.1.conv_pw.weight\n",
      "backbone.encoder.blocks.4.1.conv_pwl.weight\n",
      "backbone.encoder.blocks.4.1.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.4.1.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.4.2.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.2.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.2.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.2.conv_dw.weight\n",
      "backbone.encoder.blocks.4.2.conv_pw.weight\n",
      "backbone.encoder.blocks.4.2.conv_pwl.weight\n",
      "backbone.encoder.blocks.4.2.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.4.2.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.4.3.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.3.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.3.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.3.conv_dw.weight\n",
      "backbone.encoder.blocks.4.3.conv_pw.weight\n",
      "backbone.encoder.blocks.4.3.conv_pwl.weight\n",
      "backbone.encoder.blocks.4.3.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.4.3.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.4.4.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.4.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.4.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.4.conv_dw.weight\n",
      "backbone.encoder.blocks.4.4.conv_pw.weight\n",
      "backbone.encoder.blocks.4.4.conv_pwl.weight\n",
      "backbone.encoder.blocks.4.4.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.4.4.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.4.5.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.5.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.5.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.5.conv_dw.weight\n",
      "backbone.encoder.blocks.4.5.conv_pw.weight\n",
      "backbone.encoder.blocks.4.5.conv_pwl.weight\n",
      "backbone.encoder.blocks.4.5.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.4.5.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.4.6.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.6.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.6.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.4.6.conv_dw.weight\n",
      "backbone.encoder.blocks.4.6.conv_pw.weight\n",
      "backbone.encoder.blocks.4.6.conv_pwl.weight\n",
      "backbone.encoder.blocks.4.6.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.4.6.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.0.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.0.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.0.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.0.conv_dw.weight\n",
      "backbone.encoder.blocks.5.0.conv_pw.weight\n",
      "backbone.encoder.blocks.5.0.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.0.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.0.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.1.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.1.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.1.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.1.conv_dw.weight\n",
      "backbone.encoder.blocks.5.1.conv_pw.weight\n",
      "backbone.encoder.blocks.5.1.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.1.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.1.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.2.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.2.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.2.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.2.conv_dw.weight\n",
      "backbone.encoder.blocks.5.2.conv_pw.weight\n",
      "backbone.encoder.blocks.5.2.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.2.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.2.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.3.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.3.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.3.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.3.conv_dw.weight\n",
      "backbone.encoder.blocks.5.3.conv_pw.weight\n",
      "backbone.encoder.blocks.5.3.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.3.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.3.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.4.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.4.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.4.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.4.conv_dw.weight\n",
      "backbone.encoder.blocks.5.4.conv_pw.weight\n",
      "backbone.encoder.blocks.5.4.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.4.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.4.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.5.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.5.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.5.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.5.conv_dw.weight\n",
      "backbone.encoder.blocks.5.5.conv_pw.weight\n",
      "backbone.encoder.blocks.5.5.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.5.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.5.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.6.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.6.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.6.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.6.conv_dw.weight\n",
      "backbone.encoder.blocks.5.6.conv_pw.weight\n",
      "backbone.encoder.blocks.5.6.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.6.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.6.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.7.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.7.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.7.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.7.conv_dw.weight\n",
      "backbone.encoder.blocks.5.7.conv_pw.weight\n",
      "backbone.encoder.blocks.5.7.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.7.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.7.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.5.8.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.8.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.8.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.5.8.conv_dw.weight\n",
      "backbone.encoder.blocks.5.8.conv_pw.weight\n",
      "backbone.encoder.blocks.5.8.conv_pwl.weight\n",
      "backbone.encoder.blocks.5.8.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.5.8.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.6.0.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.0.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.0.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.0.conv_dw.weight\n",
      "backbone.encoder.blocks.6.0.conv_pw.weight\n",
      "backbone.encoder.blocks.6.0.conv_pwl.weight\n",
      "backbone.encoder.blocks.6.0.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.6.0.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.6.1.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.1.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.1.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.1.conv_dw.weight\n",
      "backbone.encoder.blocks.6.1.conv_pw.weight\n",
      "backbone.encoder.blocks.6.1.conv_pwl.weight\n",
      "backbone.encoder.blocks.6.1.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.6.1.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.blocks.6.2.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.2.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.2.bn3.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.blocks.6.2.conv_dw.weight\n",
      "backbone.encoder.blocks.6.2.conv_pw.weight\n",
      "backbone.encoder.blocks.6.2.conv_pwl.weight\n",
      "backbone.encoder.blocks.6.2.se.conv_expand.{bias, weight}\n",
      "backbone.encoder.blocks.6.2.se.conv_reduce.{bias, weight}\n",
      "backbone.encoder.bn1.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.bn2.{bias, running_mean, running_var, weight}\n",
      "backbone.encoder.conv_head.weight\n",
      "backbone.encoder.conv_stem.weight\n",
      "roi_heads.box_predictor.0.cls_score.{bias, weight}\n",
      "roi_heads.box_predictor.1.cls_score.{bias, weight}\n",
      "roi_heads.box_predictor.2.cls_score.{bias, weight}\n",
      "roi_heads.mask_head.predictor.{bias, weight}\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  backbone.fpn_lateral2.{bias, weight}\n",
      "  backbone.fpn_output2.{bias, weight}\n",
      "  backbone.fpn_lateral3.{bias, weight}\n",
      "  backbone.fpn_output3.{bias, weight}\n",
      "  backbone.fpn_lateral4.{bias, weight}\n",
      "  backbone.fpn_output4.{bias, weight}\n",
      "  backbone.fpn_lateral5.{bias, weight}\n",
      "  backbone.fpn_output5.{bias, weight}\n",
      "  backbone.bottom_up.stem.conv1.weight\n",
      "  backbone.bottom_up.stem.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.0.shortcut.weight\n",
      "  backbone.bottom_up.res2.0.shortcut.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.0.conv1.weight\n",
      "  backbone.bottom_up.res2.0.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.0.conv2.weight\n",
      "  backbone.bottom_up.res2.0.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.0.conv3.weight\n",
      "  backbone.bottom_up.res2.0.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.1.conv1.weight\n",
      "  backbone.bottom_up.res2.1.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.1.conv2.weight\n",
      "  backbone.bottom_up.res2.1.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.1.conv3.weight\n",
      "  backbone.bottom_up.res2.1.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.2.conv1.weight\n",
      "  backbone.bottom_up.res2.2.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.2.conv2.weight\n",
      "  backbone.bottom_up.res2.2.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res2.2.conv3.weight\n",
      "  backbone.bottom_up.res2.2.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.0.shortcut.weight\n",
      "  backbone.bottom_up.res3.0.shortcut.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.0.conv1.weight\n",
      "  backbone.bottom_up.res3.0.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.0.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res3.0.conv2.weight\n",
      "  backbone.bottom_up.res3.0.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.0.conv3.weight\n",
      "  backbone.bottom_up.res3.0.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.1.conv1.weight\n",
      "  backbone.bottom_up.res3.1.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.1.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res3.1.conv2.weight\n",
      "  backbone.bottom_up.res3.1.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.1.conv3.weight\n",
      "  backbone.bottom_up.res3.1.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.2.conv1.weight\n",
      "  backbone.bottom_up.res3.2.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.2.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res3.2.conv2.weight\n",
      "  backbone.bottom_up.res3.2.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.2.conv3.weight\n",
      "  backbone.bottom_up.res3.2.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.3.conv1.weight\n",
      "  backbone.bottom_up.res3.3.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.3.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res3.3.conv2.weight\n",
      "  backbone.bottom_up.res3.3.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.3.conv3.weight\n",
      "  backbone.bottom_up.res3.3.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.4.conv1.weight\n",
      "  backbone.bottom_up.res3.4.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.4.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res3.4.conv2.weight\n",
      "  backbone.bottom_up.res3.4.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.4.conv3.weight\n",
      "  backbone.bottom_up.res3.4.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.5.conv1.weight\n",
      "  backbone.bottom_up.res3.5.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.5.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res3.5.conv2.weight\n",
      "  backbone.bottom_up.res3.5.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.5.conv3.weight\n",
      "  backbone.bottom_up.res3.5.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.6.conv1.weight\n",
      "  backbone.bottom_up.res3.6.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.6.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res3.6.conv2.weight\n",
      "  backbone.bottom_up.res3.6.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.6.conv3.weight\n",
      "  backbone.bottom_up.res3.6.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.7.conv1.weight\n",
      "  backbone.bottom_up.res3.7.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.7.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res3.7.conv2.weight\n",
      "  backbone.bottom_up.res3.7.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res3.7.conv3.weight\n",
      "  backbone.bottom_up.res3.7.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.0.shortcut.weight\n",
      "  backbone.bottom_up.res4.0.shortcut.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.0.conv1.weight\n",
      "  backbone.bottom_up.res4.0.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.0.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.0.conv2.weight\n",
      "  backbone.bottom_up.res4.0.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.0.conv3.weight\n",
      "  backbone.bottom_up.res4.0.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.1.conv1.weight\n",
      "  backbone.bottom_up.res4.1.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.1.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.1.conv2.weight\n",
      "  backbone.bottom_up.res4.1.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.1.conv3.weight\n",
      "  backbone.bottom_up.res4.1.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.2.conv1.weight\n",
      "  backbone.bottom_up.res4.2.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.2.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.2.conv2.weight\n",
      "  backbone.bottom_up.res4.2.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.2.conv3.weight\n",
      "  backbone.bottom_up.res4.2.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.3.conv1.weight\n",
      "  backbone.bottom_up.res4.3.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.3.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.3.conv2.weight\n",
      "  backbone.bottom_up.res4.3.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.3.conv3.weight\n",
      "  backbone.bottom_up.res4.3.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.4.conv1.weight\n",
      "  backbone.bottom_up.res4.4.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.4.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.4.conv2.weight\n",
      "  backbone.bottom_up.res4.4.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.4.conv3.weight\n",
      "  backbone.bottom_up.res4.4.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.5.conv1.weight\n",
      "  backbone.bottom_up.res4.5.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.5.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.5.conv2.weight\n",
      "  backbone.bottom_up.res4.5.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.5.conv3.weight\n",
      "  backbone.bottom_up.res4.5.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.6.conv1.weight\n",
      "  backbone.bottom_up.res4.6.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.6.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.6.conv2.weight\n",
      "  backbone.bottom_up.res4.6.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.6.conv3.weight\n",
      "  backbone.bottom_up.res4.6.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.7.conv1.weight\n",
      "  backbone.bottom_up.res4.7.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.7.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.7.conv2.weight\n",
      "  backbone.bottom_up.res4.7.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.7.conv3.weight\n",
      "  backbone.bottom_up.res4.7.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.8.conv1.weight\n",
      "  backbone.bottom_up.res4.8.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.8.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.8.conv2.weight\n",
      "  backbone.bottom_up.res4.8.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.8.conv3.weight\n",
      "  backbone.bottom_up.res4.8.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.9.conv1.weight\n",
      "  backbone.bottom_up.res4.9.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.9.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.9.conv2.weight\n",
      "  backbone.bottom_up.res4.9.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.9.conv3.weight\n",
      "  backbone.bottom_up.res4.9.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.10.conv1.weight\n",
      "  backbone.bottom_up.res4.10.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.10.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.10.conv2.weight\n",
      "  backbone.bottom_up.res4.10.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.10.conv3.weight\n",
      "  backbone.bottom_up.res4.10.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.11.conv1.weight\n",
      "  backbone.bottom_up.res4.11.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.11.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.11.conv2.weight\n",
      "  backbone.bottom_up.res4.11.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.11.conv3.weight\n",
      "  backbone.bottom_up.res4.11.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.12.conv1.weight\n",
      "  backbone.bottom_up.res4.12.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.12.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.12.conv2.weight\n",
      "  backbone.bottom_up.res4.12.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.12.conv3.weight\n",
      "  backbone.bottom_up.res4.12.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.13.conv1.weight\n",
      "  backbone.bottom_up.res4.13.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.13.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.13.conv2.weight\n",
      "  backbone.bottom_up.res4.13.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.13.conv3.weight\n",
      "  backbone.bottom_up.res4.13.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.14.conv1.weight\n",
      "  backbone.bottom_up.res4.14.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.14.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.14.conv2.weight\n",
      "  backbone.bottom_up.res4.14.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.14.conv3.weight\n",
      "  backbone.bottom_up.res4.14.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.15.conv1.weight\n",
      "  backbone.bottom_up.res4.15.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.15.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.15.conv2.weight\n",
      "  backbone.bottom_up.res4.15.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.15.conv3.weight\n",
      "  backbone.bottom_up.res4.15.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.16.conv1.weight\n",
      "  backbone.bottom_up.res4.16.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.16.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.16.conv2.weight\n",
      "  backbone.bottom_up.res4.16.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.16.conv3.weight\n",
      "  backbone.bottom_up.res4.16.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.17.conv1.weight\n",
      "  backbone.bottom_up.res4.17.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.17.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.17.conv2.weight\n",
      "  backbone.bottom_up.res4.17.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.17.conv3.weight\n",
      "  backbone.bottom_up.res4.17.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.18.conv1.weight\n",
      "  backbone.bottom_up.res4.18.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.18.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.18.conv2.weight\n",
      "  backbone.bottom_up.res4.18.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.18.conv3.weight\n",
      "  backbone.bottom_up.res4.18.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.19.conv1.weight\n",
      "  backbone.bottom_up.res4.19.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.19.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.19.conv2.weight\n",
      "  backbone.bottom_up.res4.19.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.19.conv3.weight\n",
      "  backbone.bottom_up.res4.19.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.20.conv1.weight\n",
      "  backbone.bottom_up.res4.20.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.20.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.20.conv2.weight\n",
      "  backbone.bottom_up.res4.20.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.20.conv3.weight\n",
      "  backbone.bottom_up.res4.20.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.21.conv1.weight\n",
      "  backbone.bottom_up.res4.21.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.21.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.21.conv2.weight\n",
      "  backbone.bottom_up.res4.21.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.21.conv3.weight\n",
      "  backbone.bottom_up.res4.21.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.22.conv1.weight\n",
      "  backbone.bottom_up.res4.22.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.22.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.22.conv2.weight\n",
      "  backbone.bottom_up.res4.22.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.22.conv3.weight\n",
      "  backbone.bottom_up.res4.22.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.23.conv1.weight\n",
      "  backbone.bottom_up.res4.23.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.23.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.23.conv2.weight\n",
      "  backbone.bottom_up.res4.23.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.23.conv3.weight\n",
      "  backbone.bottom_up.res4.23.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.24.conv1.weight\n",
      "  backbone.bottom_up.res4.24.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.24.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.24.conv2.weight\n",
      "  backbone.bottom_up.res4.24.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.24.conv3.weight\n",
      "  backbone.bottom_up.res4.24.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.25.conv1.weight\n",
      "  backbone.bottom_up.res4.25.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.25.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.25.conv2.weight\n",
      "  backbone.bottom_up.res4.25.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.25.conv3.weight\n",
      "  backbone.bottom_up.res4.25.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.26.conv1.weight\n",
      "  backbone.bottom_up.res4.26.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.26.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.26.conv2.weight\n",
      "  backbone.bottom_up.res4.26.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.26.conv3.weight\n",
      "  backbone.bottom_up.res4.26.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.27.conv1.weight\n",
      "  backbone.bottom_up.res4.27.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.27.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.27.conv2.weight\n",
      "  backbone.bottom_up.res4.27.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.27.conv3.weight\n",
      "  backbone.bottom_up.res4.27.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.28.conv1.weight\n",
      "  backbone.bottom_up.res4.28.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.28.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.28.conv2.weight\n",
      "  backbone.bottom_up.res4.28.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.28.conv3.weight\n",
      "  backbone.bottom_up.res4.28.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.29.conv1.weight\n",
      "  backbone.bottom_up.res4.29.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.29.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.29.conv2.weight\n",
      "  backbone.bottom_up.res4.29.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.29.conv3.weight\n",
      "  backbone.bottom_up.res4.29.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.30.conv1.weight\n",
      "  backbone.bottom_up.res4.30.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.30.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.30.conv2.weight\n",
      "  backbone.bottom_up.res4.30.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.30.conv3.weight\n",
      "  backbone.bottom_up.res4.30.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.31.conv1.weight\n",
      "  backbone.bottom_up.res4.31.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.31.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.31.conv2.weight\n",
      "  backbone.bottom_up.res4.31.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.31.conv3.weight\n",
      "  backbone.bottom_up.res4.31.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.32.conv1.weight\n",
      "  backbone.bottom_up.res4.32.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.32.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.32.conv2.weight\n",
      "  backbone.bottom_up.res4.32.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.32.conv3.weight\n",
      "  backbone.bottom_up.res4.32.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.33.conv1.weight\n",
      "  backbone.bottom_up.res4.33.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.33.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.33.conv2.weight\n",
      "  backbone.bottom_up.res4.33.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.33.conv3.weight\n",
      "  backbone.bottom_up.res4.33.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.34.conv1.weight\n",
      "  backbone.bottom_up.res4.34.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.34.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.34.conv2.weight\n",
      "  backbone.bottom_up.res4.34.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.34.conv3.weight\n",
      "  backbone.bottom_up.res4.34.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.35.conv1.weight\n",
      "  backbone.bottom_up.res4.35.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.35.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res4.35.conv2.weight\n",
      "  backbone.bottom_up.res4.35.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res4.35.conv3.weight\n",
      "  backbone.bottom_up.res4.35.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.0.shortcut.weight\n",
      "  backbone.bottom_up.res5.0.shortcut.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.0.conv1.weight\n",
      "  backbone.bottom_up.res5.0.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.0.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res5.0.conv2.weight\n",
      "  backbone.bottom_up.res5.0.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.0.conv3.weight\n",
      "  backbone.bottom_up.res5.0.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.1.conv1.weight\n",
      "  backbone.bottom_up.res5.1.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.1.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res5.1.conv2.weight\n",
      "  backbone.bottom_up.res5.1.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.1.conv3.weight\n",
      "  backbone.bottom_up.res5.1.conv3.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.2.conv1.weight\n",
      "  backbone.bottom_up.res5.2.conv1.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.2.conv2_offset.{bias, weight}\n",
      "  backbone.bottom_up.res5.2.conv2.weight\n",
      "  backbone.bottom_up.res5.2.conv2.norm.{bias, running_mean, running_var, weight}\n",
      "  backbone.bottom_up.res5.2.conv3.weight\n",
      "  backbone.bottom_up.res5.2.conv3.norm.{bias, running_mean, running_var, weight}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/28 21:49:49 d2.engine.train_loop]: Starting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/home/ak704/.local/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/28 21:50:01 d2.utils.events]:  eta: 0:35:51  iter: 19  total_loss: 4.093  loss_cls_stage0: 0.5787  loss_box_reg_stage0: 0.7036  loss_cls_stage1: 0.5336  loss_box_reg_stage1: 0.4116  loss_cls_stage2: 0.5618  loss_box_reg_stage2: 0.181  loss_mask: 0.6898  loss_rpn_cls: 0.207  loss_rpn_loc: 0.1381  time: 0.5812  data_time: 0.0371  lr: 0.00047618  max_mem: 26034M\n",
      "[04/28 21:50:13 d2.utils.events]:  eta: 0:35:39  iter: 39  total_loss: 3.446  loss_cls_stage0: 0.4811  loss_box_reg_stage0: 0.9509  loss_cls_stage1: 0.3266  loss_box_reg_stage1: 0.5341  loss_cls_stage2: 0.1846  loss_box_reg_stage2: 0.1922  loss_mask: 0.6089  loss_rpn_cls: 0.06208  loss_rpn_loc: 0.05189  time: 0.5811  data_time: 0.0135  lr: 0.00097479  max_mem: 26034M\n",
      "[04/28 21:50:25 d2.utils.events]:  eta: 0:35:33  iter: 59  total_loss: 3.392  loss_cls_stage0: 0.475  loss_box_reg_stage0: 0.9721  loss_cls_stage1: 0.3381  loss_box_reg_stage1: 0.6  loss_cls_stage2: 0.1918  loss_box_reg_stage2: 0.2815  loss_mask: 0.4406  loss_rpn_cls: 0.035  loss_rpn_loc: 0.03271  time: 0.5820  data_time: 0.0156  lr: 0.0014734  max_mem: 26034M\n",
      "[04/28 21:50:36 d2.utils.events]:  eta: 0:35:14  iter: 79  total_loss: 3.457  loss_cls_stage0: 0.3849  loss_box_reg_stage0: 0.8712  loss_cls_stage1: 0.3699  loss_box_reg_stage1: 0.8308  loss_cls_stage2: 0.2237  loss_box_reg_stage2: 0.3752  loss_mask: 0.2975  loss_rpn_cls: 0.02746  loss_rpn_loc: 0.02986  time: 0.5801  data_time: 0.0122  lr: 0.001972  max_mem: 26034M\n",
      "[04/28 21:50:48 d2.utils.events]:  eta: 0:35:00  iter: 99  total_loss: 4.097  loss_cls_stage0: 0.3639  loss_box_reg_stage0: 0.7294  loss_cls_stage1: 0.3832  loss_box_reg_stage1: 1.118  loss_cls_stage2: 0.3357  loss_box_reg_stage2: 0.8997  loss_mask: 0.2315  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.02507  time: 0.5806  data_time: 0.0142  lr: 0.0024706  max_mem: 26034M\n",
      "[04/28 21:51:00 d2.utils.events]:  eta: 0:34:58  iter: 119  total_loss: 4.177  loss_cls_stage0: 0.4027  loss_box_reg_stage0: 0.6602  loss_cls_stage1: 0.3584  loss_box_reg_stage1: 1.013  loss_cls_stage2: 0.3747  loss_box_reg_stage2: 1.03  loss_mask: 0.193  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.02717  time: 0.5822  data_time: 0.0145  lr: 0.0024937  max_mem: 26034M\n",
      "[04/28 21:51:12 d2.utils.events]:  eta: 0:34:47  iter: 139  total_loss: 3.825  loss_cls_stage0: 0.3483  loss_box_reg_stage0: 0.5666  loss_cls_stage1: 0.3522  loss_box_reg_stage1: 0.9201  loss_cls_stage2: 0.3711  loss_box_reg_stage2: 0.9906  loss_mask: 0.1711  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.02852  time: 0.5828  data_time: 0.0168  lr: 0.0024914  max_mem: 26034M\n",
      "[04/28 21:51:23 d2.utils.events]:  eta: 0:34:35  iter: 159  total_loss: 3.504  loss_cls_stage0: 0.3094  loss_box_reg_stage0: 0.5356  loss_cls_stage1: 0.2875  loss_box_reg_stage1: 0.8071  loss_cls_stage2: 0.3419  loss_box_reg_stage2: 0.9783  loss_mask: 0.136  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.02334  time: 0.5824  data_time: 0.0140  lr: 0.0024888  max_mem: 26034M\n",
      "[04/28 21:51:35 d2.utils.events]:  eta: 0:34:23  iter: 179  total_loss: 3.528  loss_cls_stage0: 0.3144  loss_box_reg_stage0: 0.5262  loss_cls_stage1: 0.3211  loss_box_reg_stage1: 0.8552  loss_cls_stage2: 0.3418  loss_box_reg_stage2: 1.02  loss_mask: 0.1587  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.02985  time: 0.5829  data_time: 0.0152  lr: 0.0024858  max_mem: 26034M\n",
      "[04/28 21:51:47 d2.utils.events]:  eta: 0:34:11  iter: 199  total_loss: 3.281  loss_cls_stage0: 0.2576  loss_box_reg_stage0: 0.4993  loss_cls_stage1: 0.2659  loss_box_reg_stage1: 0.8111  loss_cls_stage2: 0.2965  loss_box_reg_stage2: 0.9633  loss_mask: 0.1402  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.02831  time: 0.5836  data_time: 0.0173  lr: 0.0024824  max_mem: 26034M\n",
      "[04/28 21:51:59 d2.utils.events]:  eta: 0:33:59  iter: 219  total_loss: 3.098  loss_cls_stage0: 0.2555  loss_box_reg_stage0: 0.5001  loss_cls_stage1: 0.2342  loss_box_reg_stage1: 0.753  loss_cls_stage2: 0.243  loss_box_reg_stage2: 0.9242  loss_mask: 0.1373  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.02915  time: 0.5833  data_time: 0.0124  lr: 0.0024787  max_mem: 26034M\n",
      "[04/28 21:52:11 d2.utils.events]:  eta: 0:33:49  iter: 239  total_loss: 3.184  loss_cls_stage0: 0.2238  loss_box_reg_stage0: 0.4514  loss_cls_stage1: 0.233  loss_box_reg_stage1: 0.7743  loss_cls_stage2: 0.2784  loss_box_reg_stage2: 0.9085  loss_mask: 0.1394  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.0234  time: 0.5836  data_time: 0.0153  lr: 0.0024747  max_mem: 26034M\n",
      "[04/28 21:52:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [GaussianBlur()]\n",
      "[04/28 21:52:17 d2.data.datasets.coco]: Loaded 200 images in COCO format from ../TCIA_SegPC_dataset/coco_val/COCO.json\n",
      "[04/28 21:52:17 d2.data.build]: Distribution of instances among all 1 categories:\n",
      "|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    cell    | 990          |\n",
      "|            |              |\n",
      "[04/28 21:52:17 d2.data.common]: Serializing 200 elements to byte tensors and concatenating them all ...\n",
      "[04/28 21:52:17 d2.data.common]: Serialized dataset takes 12.96 MiB\n",
      "WARNING [04/28 21:52:17 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[04/28 21:52:17 d2.evaluation.evaluator]: Start inference on 200 batches\n",
      "[04/28 21:52:20 d2.evaluation.evaluator]: Inference done 11/200. Dataloading: 0.0009 s/iter. Inference: 0.1165 s/iter. Eval: 0.1193 s/iter. Total: 0.2367 s/iter. ETA=0:00:44\n",
      "[04/28 21:52:26 d2.evaluation.evaluator]: Inference done 37/200. Dataloading: 0.0016 s/iter. Inference: 0.1135 s/iter. Eval: 0.0898 s/iter. Total: 0.2050 s/iter. ETA=0:00:33\n",
      "[04/28 21:52:31 d2.evaluation.evaluator]: Inference done 60/200. Dataloading: 0.0017 s/iter. Inference: 0.1141 s/iter. Eval: 0.0957 s/iter. Total: 0.2116 s/iter. ETA=0:00:29\n",
      "[04/28 21:52:36 d2.evaluation.evaluator]: Inference done 82/200. Dataloading: 0.0017 s/iter. Inference: 0.1159 s/iter. Eval: 0.0986 s/iter. Total: 0.2164 s/iter. ETA=0:00:25\n",
      "[04/28 21:52:41 d2.evaluation.evaluator]: Inference done 104/200. Dataloading: 0.0017 s/iter. Inference: 0.1179 s/iter. Eval: 0.0997 s/iter. Total: 0.2193 s/iter. ETA=0:00:21\n",
      "[04/28 21:52:46 d2.evaluation.evaluator]: Inference done 126/200. Dataloading: 0.0016 s/iter. Inference: 0.1176 s/iter. Eval: 0.1014 s/iter. Total: 0.2208 s/iter. ETA=0:00:16\n",
      "[04/28 21:52:51 d2.evaluation.evaluator]: Inference done 151/200. Dataloading: 0.0016 s/iter. Inference: 0.1166 s/iter. Eval: 0.1000 s/iter. Total: 0.2183 s/iter. ETA=0:00:10\n",
      "[04/28 21:52:56 d2.evaluation.evaluator]: Inference done 175/200. Dataloading: 0.0016 s/iter. Inference: 0.1166 s/iter. Eval: 0.0987 s/iter. Total: 0.2171 s/iter. ETA=0:00:05\n",
      "[04/28 21:53:01 d2.evaluation.evaluator]: Inference done 198/200. Dataloading: 0.0016 s/iter. Inference: 0.1164 s/iter. Eval: 0.1000 s/iter. Total: 0.2181 s/iter. ETA=0:00:00\n",
      "[04/28 21:53:02 d2.evaluation.evaluator]: Total inference time: 0:00:42.690323 (0.218925 s / iter per device, on 1 devices)\n",
      "[04/28 21:53:02 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.116345 s / iter per device, on 1 devices)\n",
      "[04/28 21:53:02 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[04/28 21:53:02 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n",
      "[04/28 21:53:02 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 21:53:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[04/28 21:53:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "[04/28 21:53:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 21:53:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.685\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.694\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
      "[04/28 21:53:02 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 57.655 | 75.876 | 68.479 |  nan  |  nan  | 57.655 |\n",
      "[04/28 21:53:02 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 21:53:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
      "[04/28 21:53:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "[04/28 21:53:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 21:53:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.719\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.739\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.830\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.830\n",
      "[04/28 21:53:02 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 62.419 | 76.082 | 71.876 |  nan  |  nan  | 62.427 |\n",
      "[04/28 21:53:02 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "[04/28 21:53:02 d2.engine.defaults]: Evaluation results for SegPC_val in csv format:\n",
      "[04/28 21:53:03 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[04/28 21:53:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 21:53:03 d2.evaluation.testing]: copypaste: 57.6554,75.8764,68.4787,nan,nan,57.6554\n",
      "[04/28 21:53:03 d2.evaluation.testing]: copypaste: Task: segm\n",
      "[04/28 21:53:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 21:53:03 d2.evaluation.testing]: copypaste: 62.4195,76.0818,71.8759,nan,nan,62.4270\n",
      "[04/28 21:53:08 d2.utils.events]:  eta: 0:33:37  iter: 259  total_loss: 2.896  loss_cls_stage0: 0.2205  loss_box_reg_stage0: 0.4317  loss_cls_stage1: 0.2084  loss_box_reg_stage1: 0.691  loss_cls_stage2: 0.2329  loss_box_reg_stage2: 0.9792  loss_mask: 0.1203  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.02222  time: 0.5838  data_time: 0.0168  lr: 0.0024703  max_mem: 26034M\n",
      "[04/28 21:53:21 d2.utils.events]:  eta: 0:33:31  iter: 279  total_loss: 3.128  loss_cls_stage0: 0.247  loss_box_reg_stage0: 0.3812  loss_cls_stage1: 0.2325  loss_box_reg_stage1: 0.6923  loss_cls_stage2: 0.242  loss_box_reg_stage2: 0.9571  loss_mask: 0.11  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.02925  time: 0.5853  data_time: 0.0214  lr: 0.0024656  max_mem: 26034M\n",
      "[04/28 21:53:33 d2.utils.events]:  eta: 0:33:21  iter: 299  total_loss: 2.714  loss_cls_stage0: 0.2168  loss_box_reg_stage0: 0.3939  loss_cls_stage1: 0.2307  loss_box_reg_stage1: 0.6278  loss_cls_stage2: 0.2566  loss_box_reg_stage2: 0.803  loss_mask: 0.121  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.02177  time: 0.5860  data_time: 0.0195  lr: 0.0024605  max_mem: 26034M\n",
      "[04/28 21:53:45 d2.utils.events]:  eta: 0:33:09  iter: 319  total_loss: 2.73  loss_cls_stage0: 0.2227  loss_box_reg_stage0: 0.3757  loss_cls_stage1: 0.2207  loss_box_reg_stage1: 0.6527  loss_cls_stage2: 0.2344  loss_box_reg_stage2: 0.8227  loss_mask: 0.1174  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.02692  time: 0.5860  data_time: 0.0157  lr: 0.002455  max_mem: 26034M\n",
      "[04/28 21:53:57 d2.utils.events]:  eta: 0:33:02  iter: 339  total_loss: 2.832  loss_cls_stage0: 0.2212  loss_box_reg_stage0: 0.3739  loss_cls_stage1: 0.188  loss_box_reg_stage1: 0.6996  loss_cls_stage2: 0.2024  loss_box_reg_stage2: 0.7958  loss_mask: 0.1106  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.03171  time: 0.5874  data_time: 0.0170  lr: 0.0024493  max_mem: 26034M\n",
      "[04/28 21:54:09 d2.utils.events]:  eta: 0:32:52  iter: 359  total_loss: 2.57  loss_cls_stage0: 0.2136  loss_box_reg_stage0: 0.3634  loss_cls_stage1: 0.173  loss_box_reg_stage1: 0.6416  loss_cls_stage2: 0.1701  loss_box_reg_stage2: 0.8376  loss_mask: 0.0997  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.02094  time: 0.5878  data_time: 0.0193  lr: 0.0024431  max_mem: 26034M\n",
      "[04/28 21:54:21 d2.utils.events]:  eta: 0:32:38  iter: 379  total_loss: 2.916  loss_cls_stage0: 0.221  loss_box_reg_stage0: 0.4193  loss_cls_stage1: 0.2217  loss_box_reg_stage1: 0.7162  loss_cls_stage2: 0.2367  loss_box_reg_stage2: 0.8654  loss_mask: 0.1304  loss_rpn_cls: 0.009612  loss_rpn_loc: 0.02603  time: 0.5878  data_time: 0.0174  lr: 0.0024367  max_mem: 26034M\n",
      "[04/28 21:54:33 d2.utils.events]:  eta: 0:32:27  iter: 399  total_loss: 2.684  loss_cls_stage0: 0.201  loss_box_reg_stage0: 0.3755  loss_cls_stage1: 0.1895  loss_box_reg_stage1: 0.6941  loss_cls_stage2: 0.1882  loss_box_reg_stage2: 0.8255  loss_mask: 0.1257  loss_rpn_cls: 0.009532  loss_rpn_loc: 0.02354  time: 0.5878  data_time: 0.0169  lr: 0.0024299  max_mem: 26034M\n",
      "[04/28 21:54:45 d2.utils.events]:  eta: 0:32:15  iter: 419  total_loss: 2.515  loss_cls_stage0: 0.2167  loss_box_reg_stage0: 0.3273  loss_cls_stage1: 0.2037  loss_box_reg_stage1: 0.5952  loss_cls_stage2: 0.1793  loss_box_reg_stage2: 0.7636  loss_mask: 0.09381  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.0248  time: 0.5879  data_time: 0.0171  lr: 0.0024228  max_mem: 26034M\n",
      "[04/28 21:54:57 d2.utils.events]:  eta: 0:32:06  iter: 439  total_loss: 2.482  loss_cls_stage0: 0.2119  loss_box_reg_stage0: 0.3289  loss_cls_stage1: 0.1803  loss_box_reg_stage1: 0.5641  loss_cls_stage2: 0.198  loss_box_reg_stage2: 0.8124  loss_mask: 0.1018  loss_rpn_cls: 0.01  loss_rpn_loc: 0.01924  time: 0.5883  data_time: 0.0178  lr: 0.0024153  max_mem: 26034M\n",
      "[04/28 21:55:09 d2.utils.events]:  eta: 0:31:56  iter: 459  total_loss: 2.538  loss_cls_stage0: 0.1933  loss_box_reg_stage0: 0.3479  loss_cls_stage1: 0.2116  loss_box_reg_stage1: 0.5977  loss_cls_stage2: 0.2086  loss_box_reg_stage2: 0.7212  loss_mask: 0.1031  loss_rpn_cls: 0.00842  loss_rpn_loc: 0.02347  time: 0.5889  data_time: 0.0214  lr: 0.0024075  max_mem: 26034M\n",
      "[04/28 21:55:21 d2.utils.events]:  eta: 0:31:45  iter: 479  total_loss: 2.541  loss_cls_stage0: 0.2004  loss_box_reg_stage0: 0.3504  loss_cls_stage1: 0.2173  loss_box_reg_stage1: 0.6009  loss_cls_stage2: 0.1863  loss_box_reg_stage2: 0.7441  loss_mask: 0.1036  loss_rpn_cls: 0.009334  loss_rpn_loc: 0.02497  time: 0.5892  data_time: 0.0207  lr: 0.0023994  max_mem: 26034M\n",
      "[04/28 21:55:35 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [GaussianBlur()]\n",
      "[04/28 21:55:35 d2.data.datasets.coco]: Loaded 200 images in COCO format from ../TCIA_SegPC_dataset/coco_val/COCO.json\n",
      "[04/28 21:55:35 d2.data.common]: Serializing 200 elements to byte tensors and concatenating them all ...\n",
      "[04/28 21:55:35 d2.data.common]: Serialized dataset takes 12.96 MiB\n",
      "WARNING [04/28 21:55:35 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[04/28 21:55:35 d2.evaluation.evaluator]: Start inference on 200 batches\n",
      "[04/28 21:55:38 d2.evaluation.evaluator]: Inference done 11/200. Dataloading: 0.0010 s/iter. Inference: 0.1153 s/iter. Eval: 0.0808 s/iter. Total: 0.1972 s/iter. ETA=0:00:37\n",
      "[04/28 21:55:43 d2.evaluation.evaluator]: Inference done 42/200. Dataloading: 0.0016 s/iter. Inference: 0.1132 s/iter. Eval: 0.0545 s/iter. Total: 0.1695 s/iter. ETA=0:00:26\n",
      "[04/28 21:55:48 d2.evaluation.evaluator]: Inference done 70/200. Dataloading: 0.0021 s/iter. Inference: 0.1137 s/iter. Eval: 0.0581 s/iter. Total: 0.1741 s/iter. ETA=0:00:22\n",
      "[04/28 21:55:53 d2.evaluation.evaluator]: Inference done 97/200. Dataloading: 0.0019 s/iter. Inference: 0.1143 s/iter. Eval: 0.0626 s/iter. Total: 0.1789 s/iter. ETA=0:00:18\n",
      "[04/28 21:55:58 d2.evaluation.evaluator]: Inference done 126/200. Dataloading: 0.0018 s/iter. Inference: 0.1143 s/iter. Eval: 0.0620 s/iter. Total: 0.1782 s/iter. ETA=0:00:13\n",
      "[04/28 21:56:03 d2.evaluation.evaluator]: Inference done 157/200. Dataloading: 0.0017 s/iter. Inference: 0.1136 s/iter. Eval: 0.0593 s/iter. Total: 0.1748 s/iter. ETA=0:00:07\n",
      "[04/28 21:56:08 d2.evaluation.evaluator]: Inference done 186/200. Dataloading: 0.0017 s/iter. Inference: 0.1134 s/iter. Eval: 0.0596 s/iter. Total: 0.1748 s/iter. ETA=0:00:02\n",
      "[04/28 21:56:11 d2.evaluation.evaluator]: Total inference time: 0:00:34.147277 (0.175114 s / iter per device, on 1 devices)\n",
      "[04/28 21:56:11 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.112984 s / iter per device, on 1 devices)\n",
      "[04/28 21:56:11 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[04/28 21:56:11 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n",
      "[04/28 21:56:11 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 21:56:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[04/28 21:56:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "[04/28 21:56:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 21:56:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.817\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.757\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.749\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.812\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
      "[04/28 21:56:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 64.892 | 81.722 | 75.704 |  nan  |  nan  | 64.892 |\n",
      "[04/28 21:56:11 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 21:56:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
      "[04/28 21:56:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "[04/28 21:56:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 21:56:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.819\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.790\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.786\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.851\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.851\n",
      "[04/28 21:56:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 69.053 | 81.908 | 78.983 |  nan  |  nan  | 69.055 |\n",
      "[04/28 21:56:11 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "[04/28 21:56:11 d2.engine.defaults]: Evaluation results for SegPC_val in csv format:\n",
      "[04/28 21:56:11 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[04/28 21:56:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 21:56:11 d2.evaluation.testing]: copypaste: 64.8917,81.7216,75.7039,nan,nan,64.8918\n",
      "[04/28 21:56:11 d2.evaluation.testing]: copypaste: Task: segm\n",
      "[04/28 21:56:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 21:56:11 d2.evaluation.testing]: copypaste: 69.0532,81.9077,78.9834,nan,nan,69.0549\n",
      "[04/28 21:56:11 d2.utils.events]:  eta: 0:31:34  iter: 499  total_loss: 2.361  loss_cls_stage0: 0.2003  loss_box_reg_stage0: 0.3412  loss_cls_stage1: 0.2189  loss_box_reg_stage1: 0.559  loss_cls_stage2: 0.198  loss_box_reg_stage2: 0.7241  loss_mask: 0.1045  loss_rpn_cls: 0.00989  loss_rpn_loc: 0.02554  time: 0.5898  data_time: 0.0177  lr: 0.0023909  max_mem: 26034M\n",
      "[04/28 21:56:23 d2.utils.events]:  eta: 0:31:21  iter: 519  total_loss: 2.088  loss_cls_stage0: 0.1788  loss_box_reg_stage0: 0.3019  loss_cls_stage1: 0.1509  loss_box_reg_stage1: 0.5044  loss_cls_stage2: 0.1683  loss_box_reg_stage2: 0.6598  loss_mask: 0.09041  loss_rpn_cls: 0.008326  loss_rpn_loc: 0.02456  time: 0.5899  data_time: 0.0195  lr: 0.0023822  max_mem: 26034M\n",
      "[04/28 21:56:35 d2.utils.events]:  eta: 0:31:09  iter: 539  total_loss: 2.2  loss_cls_stage0: 0.1635  loss_box_reg_stage0: 0.3248  loss_cls_stage1: 0.1396  loss_box_reg_stage1: 0.5655  loss_cls_stage2: 0.1769  loss_box_reg_stage2: 0.7329  loss_mask: 0.09004  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.02049  time: 0.5895  data_time: 0.0134  lr: 0.0023731  max_mem: 26034M\n",
      "[04/28 21:56:47 d2.utils.events]:  eta: 0:30:57  iter: 559  total_loss: 2.291  loss_cls_stage0: 0.2248  loss_box_reg_stage0: 0.3442  loss_cls_stage1: 0.2006  loss_box_reg_stage1: 0.5592  loss_cls_stage2: 0.1908  loss_box_reg_stage2: 0.6869  loss_mask: 0.1138  loss_rpn_cls: 0.008415  loss_rpn_loc: 0.02224  time: 0.5895  data_time: 0.0188  lr: 0.0023636  max_mem: 26034M\n",
      "[04/28 21:56:59 d2.utils.events]:  eta: 0:30:46  iter: 579  total_loss: 2.234  loss_cls_stage0: 0.1749  loss_box_reg_stage0: 0.3425  loss_cls_stage1: 0.1843  loss_box_reg_stage1: 0.5365  loss_cls_stage2: 0.1911  loss_box_reg_stage2: 0.669  loss_mask: 0.1048  loss_rpn_cls: 0.009839  loss_rpn_loc: 0.02008  time: 0.5895  data_time: 0.0171  lr: 0.0023539  max_mem: 26034M\n",
      "[04/28 21:57:11 d2.utils.events]:  eta: 0:30:34  iter: 599  total_loss: 2.601  loss_cls_stage0: 0.2217  loss_box_reg_stage0: 0.3659  loss_cls_stage1: 0.1891  loss_box_reg_stage1: 0.5984  loss_cls_stage2: 0.1828  loss_box_reg_stage2: 0.7175  loss_mask: 0.12  loss_rpn_cls: 0.00612  loss_rpn_loc: 0.02267  time: 0.5894  data_time: 0.0177  lr: 0.0023439  max_mem: 26034M\n",
      "[04/28 21:57:23 d2.utils.events]:  eta: 0:30:22  iter: 619  total_loss: 2.401  loss_cls_stage0: 0.2069  loss_box_reg_stage0: 0.3184  loss_cls_stage1: 0.1576  loss_box_reg_stage1: 0.5515  loss_cls_stage2: 0.1754  loss_box_reg_stage2: 0.7201  loss_mask: 0.09242  loss_rpn_cls: 0.01339  loss_rpn_loc: 0.02633  time: 0.5895  data_time: 0.0185  lr: 0.0023335  max_mem: 26034M\n",
      "[04/28 21:57:35 d2.utils.events]:  eta: 0:30:11  iter: 639  total_loss: 2.192  loss_cls_stage0: 0.1716  loss_box_reg_stage0: 0.2987  loss_cls_stage1: 0.1543  loss_box_reg_stage1: 0.5322  loss_cls_stage2: 0.136  loss_box_reg_stage2: 0.653  loss_mask: 0.08336  loss_rpn_cls: 0.007997  loss_rpn_loc: 0.02324  time: 0.5896  data_time: 0.0190  lr: 0.0023228  max_mem: 26034M\n",
      "[04/28 21:57:47 d2.utils.events]:  eta: 0:30:00  iter: 659  total_loss: 2.125  loss_cls_stage0: 0.1838  loss_box_reg_stage0: 0.3044  loss_cls_stage1: 0.1694  loss_box_reg_stage1: 0.4852  loss_cls_stage2: 0.1754  loss_box_reg_stage2: 0.6818  loss_mask: 0.08396  loss_rpn_cls: 0.007379  loss_rpn_loc: 0.01816  time: 0.5898  data_time: 0.0195  lr: 0.0023119  max_mem: 26034M\n",
      "[04/28 21:57:59 d2.utils.events]:  eta: 0:29:47  iter: 679  total_loss: 2.235  loss_cls_stage0: 0.1863  loss_box_reg_stage0: 0.3227  loss_cls_stage1: 0.1665  loss_box_reg_stage1: 0.5383  loss_cls_stage2: 0.173  loss_box_reg_stage2: 0.6786  loss_mask: 0.09866  loss_rpn_cls: 0.008416  loss_rpn_loc: 0.01935  time: 0.5899  data_time: 0.0142  lr: 0.0023006  max_mem: 26034M\n",
      "[04/28 21:58:11 d2.utils.events]:  eta: 0:29:35  iter: 699  total_loss: 2.132  loss_cls_stage0: 0.1683  loss_box_reg_stage0: 0.3201  loss_cls_stage1: 0.143  loss_box_reg_stage1: 0.5382  loss_cls_stage2: 0.1294  loss_box_reg_stage2: 0.7157  loss_mask: 0.08881  loss_rpn_cls: 0.008209  loss_rpn_loc: 0.02154  time: 0.5899  data_time: 0.0166  lr: 0.002289  max_mem: 26034M\n",
      "[04/28 21:58:22 d2.utils.events]:  eta: 0:29:23  iter: 719  total_loss: 2.068  loss_cls_stage0: 0.1713  loss_box_reg_stage0: 0.3168  loss_cls_stage1: 0.1501  loss_box_reg_stage1: 0.5107  loss_cls_stage2: 0.1392  loss_box_reg_stage2: 0.729  loss_mask: 0.09522  loss_rpn_cls: 0.008008  loss_rpn_loc: 0.01909  time: 0.5899  data_time: 0.0187  lr: 0.0022771  max_mem: 26034M\n",
      "[04/28 21:58:34 d2.utils.events]:  eta: 0:29:12  iter: 739  total_loss: 2.012  loss_cls_stage0: 0.1814  loss_box_reg_stage0: 0.2916  loss_cls_stage1: 0.1544  loss_box_reg_stage1: 0.496  loss_cls_stage2: 0.1437  loss_box_reg_stage2: 0.6362  loss_mask: 0.09939  loss_rpn_cls: 0.009541  loss_rpn_loc: 0.02204  time: 0.5898  data_time: 0.0183  lr: 0.002265  max_mem: 26034M\n",
      "[04/28 21:58:40 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [GaussianBlur()]\n",
      "[04/28 21:58:41 d2.data.datasets.coco]: Loaded 200 images in COCO format from ../TCIA_SegPC_dataset/coco_val/COCO.json\n",
      "[04/28 21:58:41 d2.data.common]: Serializing 200 elements to byte tensors and concatenating them all ...\n",
      "[04/28 21:58:41 d2.data.common]: Serialized dataset takes 12.96 MiB\n",
      "WARNING [04/28 21:58:41 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[04/28 21:58:41 d2.evaluation.evaluator]: Start inference on 200 batches\n",
      "[04/28 21:58:43 d2.evaluation.evaluator]: Inference done 11/200. Dataloading: 0.0011 s/iter. Inference: 0.1152 s/iter. Eval: 0.0586 s/iter. Total: 0.1750 s/iter. ETA=0:00:33\n",
      "[04/28 21:58:48 d2.evaluation.evaluator]: Inference done 42/200. Dataloading: 0.0018 s/iter. Inference: 0.1128 s/iter. Eval: 0.0535 s/iter. Total: 0.1682 s/iter. ETA=0:00:26\n",
      "[04/28 21:58:54 d2.evaluation.evaluator]: Inference done 69/200. Dataloading: 0.0019 s/iter. Inference: 0.1146 s/iter. Eval: 0.0615 s/iter. Total: 0.1783 s/iter. ETA=0:00:23\n",
      "[04/28 21:58:59 d2.evaluation.evaluator]: Inference done 95/200. Dataloading: 0.0020 s/iter. Inference: 0.1152 s/iter. Eval: 0.0659 s/iter. Total: 0.1832 s/iter. ETA=0:00:19\n",
      "[04/28 21:59:04 d2.evaluation.evaluator]: Inference done 124/200. Dataloading: 0.0019 s/iter. Inference: 0.1151 s/iter. Eval: 0.0648 s/iter. Total: 0.1819 s/iter. ETA=0:00:13\n",
      "[04/28 21:59:09 d2.evaluation.evaluator]: Inference done 154/200. Dataloading: 0.0018 s/iter. Inference: 0.1148 s/iter. Eval: 0.0623 s/iter. Total: 0.1791 s/iter. ETA=0:00:08\n",
      "[04/28 21:59:14 d2.evaluation.evaluator]: Inference done 182/200. Dataloading: 0.0018 s/iter. Inference: 0.1149 s/iter. Eval: 0.0624 s/iter. Total: 0.1792 s/iter. ETA=0:00:03\n",
      "[04/28 21:59:17 d2.evaluation.evaluator]: Total inference time: 0:00:35.232315 (0.180679 s / iter per device, on 1 devices)\n",
      "[04/28 21:59:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.114608 s / iter per device, on 1 devices)\n",
      "[04/28 21:59:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[04/28 21:59:18 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n",
      "[04/28 21:59:18 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 21:59:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[04/28 21:59:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "[04/28 21:59:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 21:59:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.839\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.778\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.783\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.839\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.839\n",
      "[04/28 21:59:18 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 68.366 | 83.859 | 77.751 |  nan  |  nan  | 68.367 |\n",
      "[04/28 21:59:18 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 21:59:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
      "[04/28 21:59:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "[04/28 21:59:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 21:59:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.841\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.810\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.808\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.868\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.868\n",
      "[04/28 21:59:18 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 71.740 | 84.105 | 81.035 |  nan  |  nan  | 71.742 |\n",
      "[04/28 21:59:18 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "[04/28 21:59:18 d2.engine.defaults]: Evaluation results for SegPC_val in csv format:\n",
      "[04/28 21:59:18 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[04/28 21:59:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 21:59:18 d2.evaluation.testing]: copypaste: 68.3664,83.8589,77.7514,nan,nan,68.3666\n",
      "[04/28 21:59:18 d2.evaluation.testing]: copypaste: Task: segm\n",
      "[04/28 21:59:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 21:59:18 d2.evaluation.testing]: copypaste: 71.7404,84.1049,81.0345,nan,nan,71.7422\n",
      "[04/28 21:59:24 d2.utils.events]:  eta: 0:29:00  iter: 759  total_loss: 1.92  loss_cls_stage0: 0.1838  loss_box_reg_stage0: 0.2813  loss_cls_stage1: 0.1403  loss_box_reg_stage1: 0.4346  loss_cls_stage2: 0.132  loss_box_reg_stage2: 0.6055  loss_mask: 0.08027  loss_rpn_cls: 0.005669  loss_rpn_loc: 0.01811  time: 0.5899  data_time: 0.0208  lr: 0.0022525  max_mem: 26034M\n",
      "[04/28 21:59:36 d2.utils.events]:  eta: 0:28:48  iter: 779  total_loss: 2.033  loss_cls_stage0: 0.1686  loss_box_reg_stage0: 0.3139  loss_cls_stage1: 0.1564  loss_box_reg_stage1: 0.4777  loss_cls_stage2: 0.1556  loss_box_reg_stage2: 0.5376  loss_mask: 0.09571  loss_rpn_cls: 0.007606  loss_rpn_loc: 0.01794  time: 0.5899  data_time: 0.0179  lr: 0.0022398  max_mem: 26034M\n",
      "[04/28 21:59:48 d2.utils.events]:  eta: 0:28:37  iter: 799  total_loss: 1.943  loss_cls_stage0: 0.1644  loss_box_reg_stage0: 0.3207  loss_cls_stage1: 0.1625  loss_box_reg_stage1: 0.4722  loss_cls_stage2: 0.147  loss_box_reg_stage2: 0.5939  loss_mask: 0.09103  loss_rpn_cls: 0.005077  loss_rpn_loc: 0.02108  time: 0.5900  data_time: 0.0175  lr: 0.0022268  max_mem: 26034M\n",
      "[04/28 22:00:00 d2.utils.events]:  eta: 0:28:26  iter: 819  total_loss: 2.183  loss_cls_stage0: 0.1769  loss_box_reg_stage0: 0.3007  loss_cls_stage1: 0.1895  loss_box_reg_stage1: 0.5153  loss_cls_stage2: 0.163  loss_box_reg_stage2: 0.6793  loss_mask: 0.08814  loss_rpn_cls: 0.00828  loss_rpn_loc: 0.02318  time: 0.5901  data_time: 0.0188  lr: 0.0022135  max_mem: 26034M\n",
      "[04/28 22:00:12 d2.utils.events]:  eta: 0:28:15  iter: 839  total_loss: 2.281  loss_cls_stage0: 0.2136  loss_box_reg_stage0: 0.3399  loss_cls_stage1: 0.1879  loss_box_reg_stage1: 0.5541  loss_cls_stage2: 0.1683  loss_box_reg_stage2: 0.6133  loss_mask: 0.102  loss_rpn_cls: 0.008825  loss_rpn_loc: 0.02033  time: 0.5906  data_time: 0.0223  lr: 0.0021999  max_mem: 26034M\n",
      "[04/28 22:00:24 d2.utils.events]:  eta: 0:28:04  iter: 859  total_loss: 2.03  loss_cls_stage0: 0.1856  loss_box_reg_stage0: 0.3126  loss_cls_stage1: 0.1688  loss_box_reg_stage1: 0.4709  loss_cls_stage2: 0.1862  loss_box_reg_stage2: 0.617  loss_mask: 0.1077  loss_rpn_cls: 0.006816  loss_rpn_loc: 0.02164  time: 0.5906  data_time: 0.0171  lr: 0.0021861  max_mem: 26034M\n",
      "[04/28 22:00:36 d2.utils.events]:  eta: 0:27:52  iter: 879  total_loss: 2.14  loss_cls_stage0: 0.1957  loss_box_reg_stage0: 0.3165  loss_cls_stage1: 0.1623  loss_box_reg_stage1: 0.5109  loss_cls_stage2: 0.1448  loss_box_reg_stage2: 0.6734  loss_mask: 0.09504  loss_rpn_cls: 0.007021  loss_rpn_loc: 0.02219  time: 0.5908  data_time: 0.0201  lr: 0.002172  max_mem: 26034M\n",
      "[04/28 22:00:48 d2.utils.events]:  eta: 0:27:41  iter: 899  total_loss: 1.94  loss_cls_stage0: 0.1701  loss_box_reg_stage0: 0.3282  loss_cls_stage1: 0.1852  loss_box_reg_stage1: 0.4768  loss_cls_stage2: 0.1446  loss_box_reg_stage2: 0.5959  loss_mask: 0.096  loss_rpn_cls: 0.00667  loss_rpn_loc: 0.01843  time: 0.5908  data_time: 0.0188  lr: 0.0021576  max_mem: 26034M\n",
      "[04/28 22:01:00 d2.utils.events]:  eta: 0:27:29  iter: 919  total_loss: 1.93  loss_cls_stage0: 0.1568  loss_box_reg_stage0: 0.2908  loss_cls_stage1: 0.1349  loss_box_reg_stage1: 0.4614  loss_cls_stage2: 0.1372  loss_box_reg_stage2: 0.5267  loss_mask: 0.08322  loss_rpn_cls: 0.005771  loss_rpn_loc: 0.01679  time: 0.5907  data_time: 0.0179  lr: 0.002143  max_mem: 26034M\n",
      "[04/28 22:01:12 d2.utils.events]:  eta: 0:27:18  iter: 939  total_loss: 1.959  loss_cls_stage0: 0.1929  loss_box_reg_stage0: 0.2976  loss_cls_stage1: 0.1286  loss_box_reg_stage1: 0.4606  loss_cls_stage2: 0.1433  loss_box_reg_stage2: 0.5608  loss_mask: 0.09651  loss_rpn_cls: 0.005788  loss_rpn_loc: 0.02194  time: 0.5910  data_time: 0.0232  lr: 0.0021281  max_mem: 26034M\n",
      "[04/28 22:01:25 d2.utils.events]:  eta: 0:27:07  iter: 959  total_loss: 1.906  loss_cls_stage0: 0.1593  loss_box_reg_stage0: 0.2981  loss_cls_stage1: 0.1295  loss_box_reg_stage1: 0.4253  loss_cls_stage2: 0.1485  loss_box_reg_stage2: 0.6321  loss_mask: 0.08547  loss_rpn_cls: 0.009579  loss_rpn_loc: 0.01942  time: 0.5912  data_time: 0.0180  lr: 0.002113  max_mem: 26034M\n",
      "[04/28 22:01:37 d2.utils.events]:  eta: 0:26:55  iter: 979  total_loss: 1.997  loss_cls_stage0: 0.1658  loss_box_reg_stage0: 0.2972  loss_cls_stage1: 0.1335  loss_box_reg_stage1: 0.4887  loss_cls_stage2: 0.1333  loss_box_reg_stage2: 0.6095  loss_mask: 0.08481  loss_rpn_cls: 0.006287  loss_rpn_loc: 0.02319  time: 0.5914  data_time: 0.0195  lr: 0.0020976  max_mem: 26034M\n",
      "[04/28 22:01:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [GaussianBlur()]\n",
      "[04/28 22:01:50 d2.data.datasets.coco]: Loaded 200 images in COCO format from ../TCIA_SegPC_dataset/coco_val/COCO.json\n",
      "[04/28 22:01:50 d2.data.common]: Serializing 200 elements to byte tensors and concatenating them all ...\n",
      "[04/28 22:01:50 d2.data.common]: Serialized dataset takes 12.96 MiB\n",
      "WARNING [04/28 22:01:50 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[04/28 22:01:50 d2.evaluation.evaluator]: Start inference on 200 batches\n",
      "[04/28 22:01:53 d2.evaluation.evaluator]: Inference done 11/200. Dataloading: 0.0016 s/iter. Inference: 0.1137 s/iter. Eval: 0.0545 s/iter. Total: 0.1698 s/iter. ETA=0:00:32\n",
      "[04/28 22:01:58 d2.evaluation.evaluator]: Inference done 43/200. Dataloading: 0.0025 s/iter. Inference: 0.1149 s/iter. Eval: 0.0424 s/iter. Total: 0.1599 s/iter. ETA=0:00:25\n",
      "[04/28 22:02:03 d2.evaluation.evaluator]: Inference done 73/200. Dataloading: 0.0022 s/iter. Inference: 0.1153 s/iter. Eval: 0.0458 s/iter. Total: 0.1635 s/iter. ETA=0:00:20\n",
      "[04/28 22:02:08 d2.evaluation.evaluator]: Inference done 102/200. Dataloading: 0.0021 s/iter. Inference: 0.1161 s/iter. Eval: 0.0493 s/iter. Total: 0.1676 s/iter. ETA=0:00:16\n",
      "[04/28 22:02:13 d2.evaluation.evaluator]: Inference done 132/200. Dataloading: 0.0020 s/iter. Inference: 0.1161 s/iter. Eval: 0.0499 s/iter. Total: 0.1681 s/iter. ETA=0:00:11\n",
      "[04/28 22:02:18 d2.evaluation.evaluator]: Inference done 166/200. Dataloading: 0.0020 s/iter. Inference: 0.1153 s/iter. Eval: 0.0467 s/iter. Total: 0.1641 s/iter. ETA=0:00:05\n",
      "[04/28 22:02:23 d2.evaluation.evaluator]: Inference done 198/200. Dataloading: 0.0019 s/iter. Inference: 0.1144 s/iter. Eval: 0.0471 s/iter. Total: 0.1635 s/iter. ETA=0:00:00\n",
      "[04/28 22:02:24 d2.evaluation.evaluator]: Total inference time: 0:00:31.981737 (0.164009 s / iter per device, on 1 devices)\n",
      "[04/28 22:02:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.114307 s / iter per device, on 1 devices)\n",
      "[04/28 22:02:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[04/28 22:02:24 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n",
      "[04/28 22:02:24 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 22:02:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[04/28 22:02:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "[04/28 22:02:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 22:02:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.696\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.839\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.782\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.790\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.844\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.844\n",
      "[04/28 22:02:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 69.644 | 83.943 | 78.166 |  nan  |  nan  | 69.644 |\n",
      "[04/28 22:02:24 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 22:02:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
      "[04/28 22:02:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "[04/28 22:02:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 22:02:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.840\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.810\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.798\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.856\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.856\n",
      "[04/28 22:02:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 71.559 | 84.027 | 81.045 |  nan  |  nan  | 71.560 |\n",
      "[04/28 22:02:24 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "[04/28 22:02:24 d2.engine.defaults]: Evaluation results for SegPC_val in csv format:\n",
      "[04/28 22:02:24 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[04/28 22:02:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 22:02:24 d2.evaluation.testing]: copypaste: 69.6436,83.9428,78.1664,nan,nan,69.6436\n",
      "[04/28 22:02:24 d2.evaluation.testing]: copypaste: Task: segm\n",
      "[04/28 22:02:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 22:02:24 d2.evaluation.testing]: copypaste: 71.5586,84.0268,81.0447,nan,nan,71.5598\n",
      "[04/28 22:02:24 d2.utils.events]:  eta: 0:26:43  iter: 999  total_loss: 2.073  loss_cls_stage0: 0.1627  loss_box_reg_stage0: 0.2979  loss_cls_stage1: 0.1327  loss_box_reg_stage1: 0.4921  loss_cls_stage2: 0.1394  loss_box_reg_stage2: 0.6581  loss_mask: 0.09882  loss_rpn_cls: 0.005535  loss_rpn_loc: 0.02004  time: 0.5914  data_time: 0.0195  lr: 0.002082  max_mem: 26034M\n",
      "[04/28 22:02:37 d2.utils.events]:  eta: 0:26:33  iter: 1019  total_loss: 1.922  loss_cls_stage0: 0.1602  loss_box_reg_stage0: 0.2669  loss_cls_stage1: 0.1424  loss_box_reg_stage1: 0.4207  loss_cls_stage2: 0.1167  loss_box_reg_stage2: 0.6397  loss_mask: 0.09251  loss_rpn_cls: 0.006956  loss_rpn_loc: 0.02232  time: 0.5916  data_time: 0.0174  lr: 0.0020661  max_mem: 26034M\n",
      "[04/28 22:02:49 d2.utils.events]:  eta: 0:26:22  iter: 1039  total_loss: 1.836  loss_cls_stage0: 0.1678  loss_box_reg_stage0: 0.274  loss_cls_stage1: 0.1379  loss_box_reg_stage1: 0.4697  loss_cls_stage2: 0.1339  loss_box_reg_stage2: 0.5362  loss_mask: 0.08577  loss_rpn_cls: 0.007592  loss_rpn_loc: 0.01902  time: 0.5918  data_time: 0.0153  lr: 0.00205  max_mem: 26034M\n",
      "[04/28 22:03:01 d2.utils.events]:  eta: 0:26:10  iter: 1059  total_loss: 2.009  loss_cls_stage0: 0.1714  loss_box_reg_stage0: 0.2873  loss_cls_stage1: 0.1531  loss_box_reg_stage1: 0.4879  loss_cls_stage2: 0.1682  loss_box_reg_stage2: 0.6272  loss_mask: 0.0884  loss_rpn_cls: 0.00615  loss_rpn_loc: 0.02099  time: 0.5918  data_time: 0.0179  lr: 0.0020337  max_mem: 26034M\n",
      "[04/28 22:03:13 d2.utils.events]:  eta: 0:26:01  iter: 1079  total_loss: 1.913  loss_cls_stage0: 0.1756  loss_box_reg_stage0: 0.2779  loss_cls_stage1: 0.1338  loss_box_reg_stage1: 0.439  loss_cls_stage2: 0.1154  loss_box_reg_stage2: 0.533  loss_mask: 0.08703  loss_rpn_cls: 0.007178  loss_rpn_loc: 0.01759  time: 0.5921  data_time: 0.0189  lr: 0.0020172  max_mem: 26034M\n",
      "[04/28 22:03:25 d2.utils.events]:  eta: 0:25:49  iter: 1099  total_loss: 1.769  loss_cls_stage0: 0.1537  loss_box_reg_stage0: 0.2815  loss_cls_stage1: 0.1474  loss_box_reg_stage1: 0.4615  loss_cls_stage2: 0.1369  loss_box_reg_stage2: 0.5365  loss_mask: 0.08232  loss_rpn_cls: 0.004147  loss_rpn_loc: 0.01732  time: 0.5921  data_time: 0.0177  lr: 0.0020004  max_mem: 26034M\n",
      "[04/28 22:03:37 d2.utils.events]:  eta: 0:25:38  iter: 1119  total_loss: 2.019  loss_cls_stage0: 0.1605  loss_box_reg_stage0: 0.2918  loss_cls_stage1: 0.1486  loss_box_reg_stage1: 0.4936  loss_cls_stage2: 0.1308  loss_box_reg_stage2: 0.5803  loss_mask: 0.09136  loss_rpn_cls: 0.005047  loss_rpn_loc: 0.02472  time: 0.5921  data_time: 0.0175  lr: 0.0019835  max_mem: 26034M\n",
      "[04/28 22:03:49 d2.utils.events]:  eta: 0:25:26  iter: 1139  total_loss: 1.892  loss_cls_stage0: 0.1685  loss_box_reg_stage0: 0.29  loss_cls_stage1: 0.1431  loss_box_reg_stage1: 0.429  loss_cls_stage2: 0.1599  loss_box_reg_stage2: 0.5013  loss_mask: 0.09358  loss_rpn_cls: 0.00544  loss_rpn_loc: 0.01781  time: 0.5919  data_time: 0.0154  lr: 0.0019663  max_mem: 26034M\n",
      "[04/28 22:04:01 d2.utils.events]:  eta: 0:25:15  iter: 1159  total_loss: 1.893  loss_cls_stage0: 0.1575  loss_box_reg_stage0: 0.2672  loss_cls_stage1: 0.1389  loss_box_reg_stage1: 0.4042  loss_cls_stage2: 0.134  loss_box_reg_stage2: 0.559  loss_mask: 0.08762  loss_rpn_cls: 0.005303  loss_rpn_loc: 0.01874  time: 0.5919  data_time: 0.0190  lr: 0.0019489  max_mem: 26034M\n",
      "[04/28 22:04:13 d2.utils.events]:  eta: 0:25:04  iter: 1179  total_loss: 2.043  loss_cls_stage0: 0.1919  loss_box_reg_stage0: 0.2812  loss_cls_stage1: 0.1618  loss_box_reg_stage1: 0.4548  loss_cls_stage2: 0.1492  loss_box_reg_stage2: 0.5291  loss_mask: 0.09094  loss_rpn_cls: 0.004256  loss_rpn_loc: 0.02276  time: 0.5920  data_time: 0.0209  lr: 0.0019313  max_mem: 26034M\n",
      "[04/28 22:04:25 d2.utils.events]:  eta: 0:24:51  iter: 1199  total_loss: 1.437  loss_cls_stage0: 0.1443  loss_box_reg_stage0: 0.2474  loss_cls_stage1: 0.1103  loss_box_reg_stage1: 0.3256  loss_cls_stage2: 0.1099  loss_box_reg_stage2: 0.4357  loss_mask: 0.07447  loss_rpn_cls: 0.00697  loss_rpn_loc: 0.01645  time: 0.5919  data_time: 0.0113  lr: 0.0019135  max_mem: 26034M\n",
      "[04/28 22:04:37 d2.utils.events]:  eta: 0:24:40  iter: 1219  total_loss: 1.729  loss_cls_stage0: 0.1895  loss_box_reg_stage0: 0.2736  loss_cls_stage1: 0.1382  loss_box_reg_stage1: 0.3976  loss_cls_stage2: 0.1216  loss_box_reg_stage2: 0.5003  loss_mask: 0.08726  loss_rpn_cls: 0.008258  loss_rpn_loc: 0.01725  time: 0.5918  data_time: 0.0169  lr: 0.0018956  max_mem: 26034M\n",
      "[04/28 22:04:49 d2.utils.events]:  eta: 0:24:29  iter: 1239  total_loss: 1.804  loss_cls_stage0: 0.1465  loss_box_reg_stage0: 0.2741  loss_cls_stage1: 0.1639  loss_box_reg_stage1: 0.402  loss_cls_stage2: 0.1611  loss_box_reg_stage2: 0.5163  loss_mask: 0.09382  loss_rpn_cls: 0.007814  loss_rpn_loc: 0.01968  time: 0.5917  data_time: 0.0148  lr: 0.0018774  max_mem: 26034M\n",
      "[04/28 22:04:55 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [GaussianBlur()]\n",
      "[04/28 22:04:55 d2.data.datasets.coco]: Loaded 200 images in COCO format from ../TCIA_SegPC_dataset/coco_val/COCO.json\n",
      "[04/28 22:04:55 d2.data.common]: Serializing 200 elements to byte tensors and concatenating them all ...\n",
      "[04/28 22:04:55 d2.data.common]: Serialized dataset takes 12.96 MiB\n",
      "WARNING [04/28 22:04:55 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "[04/28 22:04:55 d2.evaluation.evaluator]: Start inference on 200 batches\n",
      "[04/28 22:04:57 d2.evaluation.evaluator]: Inference done 11/200. Dataloading: 0.0010 s/iter. Inference: 0.1177 s/iter. Eval: 0.0559 s/iter. Total: 0.1745 s/iter. ETA=0:00:32\n",
      "[04/28 22:05:02 d2.evaluation.evaluator]: Inference done 43/200. Dataloading: 0.0015 s/iter. Inference: 0.1150 s/iter. Eval: 0.0439 s/iter. Total: 0.1605 s/iter. ETA=0:00:25\n",
      "[04/28 22:05:08 d2.evaluation.evaluator]: Inference done 72/200. Dataloading: 0.0016 s/iter. Inference: 0.1153 s/iter. Eval: 0.0504 s/iter. Total: 0.1675 s/iter. ETA=0:00:21\n",
      "[04/28 22:05:13 d2.evaluation.evaluator]: Inference done 101/200. Dataloading: 0.0017 s/iter. Inference: 0.1154 s/iter. Eval: 0.0525 s/iter. Total: 0.1696 s/iter. ETA=0:00:16\n",
      "[04/28 22:05:18 d2.evaluation.evaluator]: Inference done 131/200. Dataloading: 0.0016 s/iter. Inference: 0.1149 s/iter. Eval: 0.0531 s/iter. Total: 0.1697 s/iter. ETA=0:00:11\n",
      "[04/28 22:05:23 d2.evaluation.evaluator]: Inference done 164/200. Dataloading: 0.0016 s/iter. Inference: 0.1141 s/iter. Eval: 0.0503 s/iter. Total: 0.1661 s/iter. ETA=0:00:05\n",
      "[04/28 22:05:28 d2.evaluation.evaluator]: Inference done 194/200. Dataloading: 0.0016 s/iter. Inference: 0.1136 s/iter. Eval: 0.0512 s/iter. Total: 0.1665 s/iter. ETA=0:00:00\n",
      "[04/28 22:05:29 d2.evaluation.evaluator]: Total inference time: 0:00:32.526996 (0.166805 s / iter per device, on 1 devices)\n",
      "[04/28 22:05:29 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.113461 s / iter per device, on 1 devices)\n",
      "[04/28 22:05:29 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[04/28 22:05:29 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n",
      "[04/28 22:05:29 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 22:05:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[04/28 22:05:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "[04/28 22:05:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 22:05:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.840\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.787\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.799\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.853\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.853\n",
      "[04/28 22:05:29 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 69.820 | 83.951 | 78.709 |  nan  |  nan  | 69.820 |\n",
      "[04/28 22:05:29 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "[04/28 22:05:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
      "[04/28 22:05:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "[04/28 22:05:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[04/28 22:05:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.722\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.841\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.819\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.871\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.871\n",
      "[04/28 22:05:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 72.186 | 84.067 | 81.895 |  nan  |  nan  | 72.187 |\n",
      "[04/28 22:05:29 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "[04/28 22:05:29 d2.engine.defaults]: Evaluation results for SegPC_val in csv format:\n",
      "[04/28 22:05:29 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[04/28 22:05:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 22:05:29 d2.evaluation.testing]: copypaste: 69.8202,83.9507,78.7092,nan,nan,69.8202\n",
      "[04/28 22:05:29 d2.evaluation.testing]: copypaste: Task: segm\n",
      "[04/28 22:05:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[04/28 22:05:29 d2.evaluation.testing]: copypaste: 72.1860,84.0668,81.8947,nan,nan,72.1870\n",
      "[04/28 22:05:35 d2.utils.events]:  eta: 0:24:16  iter: 1259  total_loss: 1.746  loss_cls_stage0: 0.1754  loss_box_reg_stage0: 0.2618  loss_cls_stage1: 0.1313  loss_box_reg_stage1: 0.4056  loss_cls_stage2: 0.1402  loss_box_reg_stage2: 0.5207  loss_mask: 0.0837  loss_rpn_cls: 0.005011  loss_rpn_loc: 0.01633  time: 0.5917  data_time: 0.0148  lr: 0.0018591  max_mem: 26034M\n",
      "[04/28 22:05:47 d2.utils.events]:  eta: 0:24:04  iter: 1279  total_loss: 1.693  loss_cls_stage0: 0.1615  loss_box_reg_stage0: 0.2618  loss_cls_stage1: 0.1346  loss_box_reg_stage1: 0.3945  loss_cls_stage2: 0.1267  loss_box_reg_stage2: 0.4354  loss_mask: 0.08468  loss_rpn_cls: 0.00414  loss_rpn_loc: 0.01514  time: 0.5916  data_time: 0.0140  lr: 0.0018406  max_mem: 26034M\n",
      "[04/28 22:05:59 d2.utils.events]:  eta: 0:23:51  iter: 1299  total_loss: 1.836  loss_cls_stage0: 0.177  loss_box_reg_stage0: 0.3073  loss_cls_stage1: 0.1253  loss_box_reg_stage1: 0.4923  loss_cls_stage2: 0.153  loss_box_reg_stage2: 0.5472  loss_mask: 0.08618  loss_rpn_cls: 0.005588  loss_rpn_loc: 0.01801  time: 0.5914  data_time: 0.0150  lr: 0.0018219  max_mem: 26034M\n",
      "[04/28 22:06:11 d2.utils.events]:  eta: 0:23:40  iter: 1319  total_loss: 1.846  loss_cls_stage0: 0.1531  loss_box_reg_stage0: 0.2585  loss_cls_stage1: 0.1086  loss_box_reg_stage1: 0.4449  loss_cls_stage2: 0.1133  loss_box_reg_stage2: 0.5566  loss_mask: 0.08196  loss_rpn_cls: 0.003709  loss_rpn_loc: 0.02047  time: 0.5914  data_time: 0.0155  lr: 0.0018031  max_mem: 26034M\n",
      "[04/28 22:06:23 d2.utils.events]:  eta: 0:23:26  iter: 1339  total_loss: 1.808  loss_cls_stage0: 0.1404  loss_box_reg_stage0: 0.2659  loss_cls_stage1: 0.156  loss_box_reg_stage1: 0.4458  loss_cls_stage2: 0.1249  loss_box_reg_stage2: 0.5434  loss_mask: 0.07884  loss_rpn_cls: 0.0057  loss_rpn_loc: 0.01598  time: 0.5913  data_time: 0.0163  lr: 0.0017841  max_mem: 26034M\n",
      "[04/28 22:06:35 d2.utils.events]:  eta: 0:23:14  iter: 1359  total_loss: 1.592  loss_cls_stage0: 0.1566  loss_box_reg_stage0: 0.2582  loss_cls_stage1: 0.1483  loss_box_reg_stage1: 0.3573  loss_cls_stage2: 0.1326  loss_box_reg_stage2: 0.4242  loss_mask: 0.0729  loss_rpn_cls: 0.003765  loss_rpn_loc: 0.01992  time: 0.5912  data_time: 0.0128  lr: 0.001765  max_mem: 26034M\n"
     ]
    }
   ],
   "source": [
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a759c1-dfb1-4d1b-a1e1-30202c5132b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "\n",
    "# for d in random.sample(train_dicts, 3):\n",
    "#     print(d[\"file_name\"])\n",
    "#     img = cv2.imread(d[\"file_name\"])\n",
    "#     visualizer = Visualizer(img[:, :, ::-1], metadata=train_meta, instance_mode=ColorMode.IMAGE_BW, scale=1)\n",
    "#     out = visualizer.draw_dataset_dict(d)\n",
    "#     plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e89c6-b0fd-4aec-80e5-3292f2732bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
